# NLP2CMD jako Backend Webowy

Ten dokument opisuje jak uÅ¼ywaÄ‡ NLP2CMD jako backendu w aplikacjach webowych.

## ğŸ“‹ Spis treÅ›ci

1. [Wprowadzenie](#wprowadzenie)
2. [Instalacja](#instalacja)
3. [Szybki start](#szybki-start)
4. [PrzykÅ‚ady integracji](#przykÅ‚ady-integracji)
5. [API Reference](#api-reference)
6. [Konfiguracja](#konfiguracja)
7. [PrzykÅ‚ady uÅ¼ycia](#przykÅ‚ady-uÅ¼ycia)

## ğŸš€ Wprowadzenie

NLP2CMD moÅ¼e byÄ‡ uÅ¼ywany jako backend w aplikacjach webowych do:
- PrzeksztaÅ‚cania jÄ™zyka naturalnego w komendy
- Automatyzacji zadaÅ„ DevOps
- Generowania konfiguracji
- ZarzÄ…dzania kontenerami

### Kluczowe funkcje

- âœ… **Wsparcie dla jÄ™zyka polskiego i angielskiego**
- âœ… **LLM fallback z Ollama** (bez potrzeby API keys)
- âœ… **Auto-instalacja zaleÅ¼noÅ›ci**
- âœ… **Wiele DSL: shell, docker, kubernetes**
- âœ… **REST API**
- âœ… **Historia komend**
- âœ… **ZarzÄ…dzanie usÅ‚ugami**

## ğŸ“¦ Instalacja

```bash
# Klonuj repozytorium
git clone https://github.com/wronai/nlp2cmd.git
cd nlp2cmd

# Zainstaluj zaleÅ¼noÅ›ci
pip install -e .

# Dla web API (opcjonalnie)
pip install fastapi uvicorn jinja2
```

## âš¡ Szybki start

### 1. Uruchomienie przykÅ‚adowej aplikacji

```bash
cd examples/devops
python web_app_example.py
```

OtwÃ³rz http://localhost:8000 w przeglÄ…darce.

### 2. UÅ¼ycie jako moduÅ‚

```python
from nlp2cmd_web_controller import NLP2CMDWebController

# Inicjalizacja
controller = NLP2CMDWebController(
    use_llm_fallback=True,
    auto_install=True
)

# UÅ¼ycie
result = await controller.execute("Uruchom docker na porcie 8080")
print(result["command"])  # docker run -d -p 8080:8080 nginx
```

## ğŸ”§ PrzykÅ‚ady integracji

### FastAPI

```python
from fastapi import FastAPI
from nlp2cmd_web_controller import NLP2CMDWebAPI

app = FastAPI()
nlp_api = NLP2CMDWebAPI()

@app.post("/process")
async def process_command(command: str, dsl: str = "auto"):
    result = await nlp_api.process_command(command, dsl)
    return result
```

### Flask

```python
from flask import Flask, request, jsonify
from nlp2cmd_web_controller import NLP2CMDWebAPI
import asyncio

app = Flask(__name__)
nlp_api = NLP2CMDWebAPI()

@app.route('/process', methods=['POST'])
def process_command():
    data = request.get_json()
    result = asyncio.run(nlp_api.process_command(
        data['command'], 
        data.get('dsl', 'auto')
    ))
    return jsonify(result)
```

### Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY . .

RUN pip install -e .
RUN pip install fastapi uvicorn

EXPOSE 8000

CMD ["uvicorn", "web_app_example:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“š API Reference

### Endpoints

#### POST /api/process
Przetwarza komendÄ™ z jÄ™zyka naturalnego.

**Request:**
```json
{
    "command": "Uruchom docker",
    "dsl": "auto"
}
```

**Response:**
```json
{
    "status": "success",
    "command": "docker run -d -p 8080:8080 nginx",
    "dsl": "docker",
    "action": "llm_fallback",
    "llm_used": true,
    "message": "Wygenerowano komendÄ™ za pomocÄ… LLM fallback"
}
```

#### GET /api/status
Zwraca status i moÅ¼liwoÅ›ci API.

#### GET /api/history?limit=10
Zwraca historiÄ™ komend.

#### GET /api/services
Zwraca wdroÅ¼one usÅ‚ugi.

#### GET /api/examples
Zwraca przykÅ‚adowe komendy.

### Typy DSL

- `auto` - Automatyczne wykrycie
- `shell` - Komendy shell
- `docker` - Komendy Docker
- `kubernetes` - Komendy Kubernetes

## âš™ï¸ Konfiguracja

### Zmienne Å›rodowiskowe

```bash
# Model LLM (domyÅ›lnie: ollama/qwen2.5-coder:7b)
export NLP2CMD_LLM_MODEL="ollama/llama3:8b"

# API base LLM (domyÅ›lnie: http://localhost:11434)
export NLP2CMD_LLM_API_BASE="http://localhost:11434"

# Timeout LLM (domyÅ›lnie: 30s)
export NLP2CMD_LLM_TIMEOUT="60"
```

### Opcje kontrolera

```python
controller = NLP2CMDWebController(
    output_dir="./generated",      # Katalog na wygenerowane pliki
    use_llm_fallback=True,        # UÅ¼yj LLM fallback
    auto_install=False            # Auto-instalacja zaleÅ¼noÅ›ci
)
```

## ğŸ’¡ PrzykÅ‚ady uÅ¼ycia

### DevOps automation

```python
# WdroÅ¼enie serwisu
result = await controller.execute("Uruchom serwis czatu na porcie 8080 z Redis")

# ZarzÄ…dzanie kontenerami
result = await controller.execute("PokaÅ¼ logi kontenera nginx")

# Skalowanie
result = await controller.execute("Skaluj serwis do 3 replik")
```

### Generowanie konfiguracji

```python
# Konfiguracja email
result = await controller.execute("Skonfiguruj email dla jan@example.com")

# Baza danych
result = await controller.execute("StwÃ³rz bazÄ™ PostgreSQL z hasÅ‚em")
```

### Shell commands

```python
# Pliki
result = await controller.execute("StwÃ³rz plik konfiguracyjny JSON")

# System
result = await controller.execute("PokaÅ¼ zuÅ¼ycie dysku")
```

## ğŸ”’ BezpieczeÅ„stwo

### Best practices

1. **Walidacja inputÃ³w** - Zawsze waliduj komendy przed wykonaniem
2. **Sandboxing** - Uruchamiaj komendy w izolowanym Å›rodowisku
3. **Logowanie** - Loguj wszystkie komendy i wyniki
4. **Limitowanie** - Ustaw limity na czas i zasoby

### PrzykÅ‚ad walidacji

```python
import re

def validate_command(command: str) -> bool:
    # Blokuj niebezpieczne komendy
    dangerous = ['rm -rf', 'sudo', 'chmod 777', '> /dev/sda']
    for bad in dangerous:
        if bad in command:
            return False
    return True
```

## ğŸš€ WdraÅ¼anie

### Docker Compose

```yaml
version: '3.8'
services:
  nlp2cmd-api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - NLP2CMD_LLM_MODEL=ollama/qwen2.5-coder:7b
    volumes:
      - ./generated:/app/generated
  
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

volumes:
  ollama_data:
```

### Kubernetes

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nlp2cmd-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nlp2cmd-api
  template:
    metadata:
      labels:
        app: nlp2cmd-api
    spec:
      containers:
      - name: api
        image: nlp2cmd:latest
        ports:
        - containerPort: 8000
        env:
        - name: NLP2CMD_LLM_MODEL
          value: "ollama/qwen2.5-coder:7b"
```

## ğŸ› ï¸ Rozszerzenia

### Dodawanie wÅ‚asnych adapterÃ³w

```python
from nlp2cmd.adapters.base import BaseDSLAdapter

class CustomAdapter(BaseDSLAdapter):
    def transform(self, text: str):
        # WÅ‚asna logika transformacji
        return TransformResult(
            command="custom-command",
            dsl_type="custom"
        )

# UÅ¼ycie
controller.nlp2cmd_instances["custom"] = NLP2CMD(
    adapter=CustomAdapter()
)
```

### WÅ‚asne szablony

```python
def _create_custom_template(self, entities: dict) -> ServiceConfig:
    return ServiceConfig(
        name="custom-service",
        service_type=ServiceType.CUSTOM,
        port=entities.get("port", 9000),
        image="custom:latest",
    )

controller.templates[ServiceType.CUSTOM] = _create_custom_template
```

## ğŸ“ PrzykÅ‚ady komend

### Polskie
- "Uruchom docker"
- "PokaÅ¼ logi kontenera"
- "StwÃ³rz plik konfiguracyjny"
- "Skaluj serwis do 5 replik"
- "Zrestartuj bazÄ™ danych"

### Angielskie
- "Deploy docker container"
- "Show container logs"
- "Create config file"
- "Scale service to 5 replicas"
- "Restart database"

## ğŸ¤ WspÃ³Å‚praca

- GitHub: https://github.com/wronai/nlp2cmd
- Dokumentacja: https://nlp2cmd.readthedocs.io
- Issues: https://github.com/wronai/nlp2cmd/issues

## ğŸ“„ Licencja

MIT License - zobacz plik LICENSE dla szczegÃ³Å‚Ã³w.
