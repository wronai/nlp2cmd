#!/usr/bin/env python3
"""
NLP2CMD - Kompletne przyk≈Çady u≈ºycia: Python API + Shell Commands

Demonstruje oba sposoby u≈ºycia NLP2CMD:
1. Przez Python API (HybridThermodynamicGenerator)
2. Przez komendy shell bezpo≈õrednio

Autor: NLP2CMD Team
Wersja: 1.0.4
"""

import asyncio
import subprocess
import sys
import time
from pathlib import Path

sys.path.append(str(Path(__file__).resolve().parents[1]))

from _demo_helpers import (
    print_full_result as _print_full_result,
    print_rule,
    print_separator as _print_separator,
)
from nlp2cmd.generation.thermodynamic import HybridThermodynamicGenerator


def print_separator(title: str):
    """Drukuj ≈Çadny separator z tytu≈Çem."""
    _print_separator(title, leading_newline=True, width=80)


def print_result(query: str, result: dict, elapsed: float, source: str = "Python API"):
    """Wy≈õwietl wynik w standardowym formacie."""
    _print_full_result(query, result, elapsed, source=source)


async def demo_python_api():
    """Demonstracja u≈ºycia Python API."""
    print_separator("Python API - Przyk≈Çady u≈ºycia")
    
    generator = HybridThermodynamicGenerator()
    
    # Przyk≈Çady zapyta≈Ñ pokazujƒÖce r√≥≈ºne scenariusze
    examples = [
        # Proste zapytania ‚Üí DSL generation
        ("Poka≈º u≈ºytkownik√≥w", "dsl"),
        ("Znajd≈∫ pliki .log wiƒôksze ni≈º 10MB", "dsl"),
        ("Uruchom serwer nginx", "dsl"),
        
        # Optymalizacja ‚Üí Thermodynamic sampling
        ("Zoptymalizuj przydzielanie zasob√≥w", "thermodynamic"),
        ("Minimalizuj koszty transportu", "thermodynamic"),
        ("Znajd≈∫ optymalne ustawienia parametr√≥w", "thermodynamic"),
        
        # Z≈Ço≈ºone operacje systemowe
        ("Sprawd≈∫ stan systemu i zasob√≥w", "dsl"),
        ("Stw√≥rz backup i skompresuj dane", "dsl"),
    ]
    
    print("üêç U≈ºycie przez Python API:")
    print("from nlp2cmd.generation import HybridThermodynamicGenerator")
    print("generator = HybridThermodynamicGenerator()")
    print("result = await generator.generate('twoje zapytanie')")
    print()
    
    for query, expected_source in examples:
        start_time = time.time()
        result = await generator.generate(query)
        elapsed = (time.time() - start_time) * 1000
        
        print_result(query, result, elapsed)
        
        # Weryfikacja ≈∫r√≥d≈Ça
        if result['source'] != expected_source:
            print(f"‚ö†Ô∏è  Oczekiwano ≈∫r√≥d≈Ça: {expected_source}, otrzymano: {result['source']}")


def demo_shell_commands():
    """Demonstracja komend shell."""
    print_separator("Shell Commands - Bezpo≈õrednie u≈ºycie w terminalu")
    
    # Przyk≈Çady komend shell z nlp2cmd
    shell_examples = [
        # Podstawowe komendy
        "nlp2cmd 'Poka≈º u≈ºytkownik√≥w'",
        "nlp2cmd 'Znajd≈∫ pliki .tmp do usuniƒôcia'",
        "nlp2cmd 'Sprawd≈∫ u≈ºycie dysku'",
        
        # Z opcjami
        "nlp2cmd --dsl shell 'Uruchom serwer apache'",
        "nlp2cmd --explain 'Zoptymalizuj zu≈ºycie pamiƒôci'",
        "nlp2cmd --auto-repair 'Napraw konfiguracjƒô nginx'",
        
        # Interaktywny tryb
        "nlp2cmd --interactive",
        
        # Analityczne komendy
        "nlp2cmd analyze-env",
        "nlp2cmd validate config.json",
        "nlp2cmd repair docker-compose.yml --backup",
        
        # Termodynamiczne zapytania
        "nlp2cmd 'Zoptymalizuj rozk≈Çad obciƒÖ≈ºenia'",
        "nlp2cmd 'Minimalizuj czas odpowiedzi serwera'",
    ]
    
    print("üíª U≈ºycie przez komendy shell:")
    print("# Instalacja:")
    print("pip install nlp2cmd")
    print()
    print("# Podstawowe u≈ºycie:")
    print("nlp2cmd 'twoje zapytanie w jƒôzyku naturalnym'")
    print()
    print("# Z opcjami:")
    print("nlp2cmd --dsl shell 'polecenie shell'")
    print("nlp2cmd --dsl sql 'zapytanie SQL'")
    print("nlp2cmd --dsl docker 'komenda Docker'")
    print("nlp2cmd --dsl kubernetes 'komenda K8s'")
    print()
    print("# Tryb interaktywny:")
    print("nlp2cmd --interactive")
    print()
    print("# Analiza ≈õrodowiska:")
    print("nlp2cmd analyze-env --output environment.json")
    print()
    print("# Walidacja i naprawa plik√≥w:")
    print("nlp2cmd validate plik.conf")
    print("nlp2cmd repair plik.conf --backup")
    print()
    print("\nüìã Przyk≈Çady komend:")
    
    for cmd in shell_examples:
        print(f"  {cmd}")


async def demo_mixed_usage():
    """Demonstracja mieszanego u≈ºycia Python + shell."""
    print_separator("Mieszane u≈ºycie - Python + Shell")
    
    print("üîÑ Scenariusz: Analiza systemu + optymalizacja")
    print()
    
    # Krok 1: Analiza ≈õrodowiska przez shell
    print("1Ô∏è‚É£ Analiza ≈õrodowiska (shell):")
    print("   $ nlp2cmd analyze-env")
    
    try:
        result = subprocess.run(
            ["nlp2cmd", "analyze-env"], 
            capture_output=True, 
            text=True, 
            timeout=30
        )
        if result.returncode == 0:
            print("   ‚úÖ Analiza zako≈Ñczona pomy≈õlnie")
        else:
            print(f"   ‚ö†Ô∏è B≈ÇƒÖd: {result.stderr}")
    except (subprocess.TimeoutExpired, FileNotFoundError):
        print("   ‚ÑπÔ∏è Symulacja wynik√≥w analizy ≈õrodowiska")
        print("   üñ•Ô∏è System: Linux")
        print("   üõ†Ô∏è Narzƒôdzia: docker, kubectl, python3")
        print("   üìÅ Pliki konfiguracyjne: 5 znalezionych")
    
    print()
    
    # Krok 2: Generowanie komend przez Python API
    print("2Ô∏è‚É£ Generowanie komend optymalizacyjnych (Python API):")
    
    generator = HybridThermodynamicGenerator()
    
    optimization_queries = [
        "Zoptymalizuj zu≈ºycie pamiƒôci w systemie",
        "Zoptymalizuj przydzielanie CPU dla proces√≥w",
        "Minimalizuj czas odpowiedzi aplikacji",
    ]
    
    for query in optimization_queries:
        start_time = time.time()
        result = await generator.generate(query)
        elapsed = (time.time() - start_time) * 1000
        
        print_result(query, result, elapsed)
        
        # Krok 3: Wykonanie komendy przez shell
        if result['source'] == 'dsl' and result['result'].command:
            cmd = result['result'].command
            print(f"   üîÑ Wykonanie: {cmd}")
            
            # Symulacja wykonania (bez faktycznego uruchamiania)
            print("   ‚ÑπÔ∏è Symulacja wykonania komendy...")
            print("   ‚úÖ Komenda wykonana pomy≈õlnie")


def demo_advanced_features():
    """Demonstracja zaawansowanych funkcji."""
    print_separator("Zaawansowane funkcje")
    
    print("üöÄ Zaawansowane opcje Python API:")
    print("""
# Z kontekstem ≈õrodowiska
context = {
    'os': 'linux',
    'shell': 'bash',
    'available_tools': ['docker', 'kubectl'],
    'environment_variables': {'PATH': '/usr/bin:/bin'}
}
result = await generator.generate('zapytanie', context=context)

# Batch processing
queries = ['zapytanie1', 'zapytanie2', 'zapytanie3']
results = await asyncio.gather(*[
    generator.generate(q) for q in queries
])
""")
    
    print("üöÄ Zaawansowane opcje Shell:")
    print("""
# Pipeline komend
nlp2cmd 'znajd≈∫ logi b≈Çƒôd√≥w' | nlp2cmd 'filtruj ostatnie 24h'

# Z pliku wej≈õciowego
nlp2cmd --file queries.txt

# Eksport wynik√≥w
nlp2cmd 'analizuj system' --output results.json

# Custom DSL
nlp2cmd --dsl custom 'zapytanie w custom DSL'
""")


async def main():
    """G≈Ç√≥wna funkcja demonstracyjna."""
    print("üéØ NLP2CMD - Kompletne przyk≈Çady u≈ºycia")
    print("üìö Python API + Shell Commands")
    print_rule(width=80, char="=")
    
    start_total = time.time()
    
    # Sekcje demonstracyjne
    await demo_python_api()
    demo_shell_commands()
    await demo_mixed_usage()
    demo_advanced_features()
    
    total_time = (time.time() - start_total) * 1000
    
    print_separator("Podsumowanie")
    print(f"‚è±Ô∏è Ca≈Çkowity czas demonstracji: {total_time:.1f}ms")
    print()
    print("‚úÖ Wersja: 1.0.4")
    print("üìñ Dokumentacja: https://github.com/wronai/nlp2cmd")
    print("üêõ Bug reports: https://github.com/wronai/nlp2cmd/issues")
    print()
    print("üéâ Dziƒôki za u≈ºycie NLP2CMD!")
    print_rule(width=80, char="=")


if __name__ == "__main__":
    asyncio.run(main())
