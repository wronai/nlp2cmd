# NLP2CMD Configuration

# Schema Generation
schema_generation:
  # Use LLM for enhanced schema generation
  use_llm: true
  llm:
    provider: litellm
    model: ollama/qwen2.5-coder:7b
    api_base: http://localhost:11434
    api_key: ""
    temperature: 0.1
    max_tokens: 2048
    timeout: 30
  
  # Fallback to non-LLM generation
  fallback_to_non_llm: true
  
  # Batch processing
  batch_size: 10
  max_commands: 100

# Testing Configuration
test_commands:
  # List of commands to test (100 commands)
  - find
  - grep
  - sed
  - awk
  - ls
  - cd
  - mkdir
  - rm
  - cp
  - mv
  - ps
  - top
  - kill
  - killall
  - systemctl
  - service
  - docker
  - docker-compose
  - kubectl
  - git
  - curl
  - wget
  - ping
  - netstat
  - ss
  - lsof
  - df
  - du
  - free
  - uname
  - whoami
  - id
  - chmod
  - chown
  - chgrp
  - tar
  - zip
  - unzip
  - gzip
  - gunzip
  - ssh
  - scp
  - rsync
  - history
  - alias
  - export
  - echo
  - printf
  - cat
  - less
  - more
  - head
  - tail
  - sort
  - uniq
  - wc
  - tr
  - cut
  - paste
  - join
  - split
  - xargs
  - find
  - locate
  - which
  - whereis
  - type
  - man
  - info
  - help
  - date
  - cal
  - uptime
  - time
  - sleep
  - watch
  - nohup
  - bg
  - fg
  - jobs
  - disown
  - kill
  - pkill
  - pgrep
  - pidof
  - nice
  - renice
  - ionice
  - timeout
  - flock
  - screen
  - tmux
  - vim
  - nano
  - emacs
  - code
  - python
  - python3
  - pip
  - pip3
  - npm
  - yarn
  - node
  - java
  - javac
  - gcc
  - g++
  - make
  - cmake
  - cargo
  - rustc
  - go
  - ruby
  - gem
  - perl
  - php
